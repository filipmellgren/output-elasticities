library(prodest)
library(data.table)
data(chilean)
head(chilean)

gmm_loss <- function(params, idvar, timevar, output_pred, input) {
  
  degree <- sqrt(length(params) - 1)

  d <- data.table(input)
  d$idvar <- idvar
  d$timevar <- timevar

  d$output_pred <- output_pred
  setnames(d, c("1.0.0", "0.1.0"), c("labor", "capital"))

  d$labor.lag <- lagPanel(idvar, timevar, d$labor)
  d$capital.lag <- lagPanel(idvar, timevar, d$capital)
  d$output.lag <- lagPanel(idvar, timevar, d$output_pred)

  d <- na.omit(d)

  prod_vars <- polym(d$labor, d$capital, degree = degree, raw = TRUE)
  d$prod_est <- d$output_pred - prod_vars %*% params

  prod_vars.lag <- polym(d$labor.lag, d$capital.lag, degree = degree, raw = TRUE)
  prodest_lag <- d$output.lag - prod_vars.lag %*% params

  g_prod <- polym(prodest_lag, degree = 3, raw = TRUE)

  Z <- polym(d$labor.lag, d$capital, degree = degree, raw = TRUE)
  W <- solve(crossprod(Z)) / nrow(d)

  expected_prod <- fitted(lm(d$prod_est ~ g_prod))

  XI <- d$prod_est - expected_prod # Productivity shocks

  crit <- t(crossprod(Z, XI)) %*% W %*% (crossprod(Z, XI))

  return(crit)
}

prod_est <- function(output, labor, capital, material, idvar, timevar, degree = 2) {
  #' Estimate production function parameters
  #' Caution: Results can be unstable and depend on optimization algorithm.
  #' Need to implement bootstrapped standard errors to quantify uncertainty.
  #' 
  #' In the first stage, predict the production function.
  #' we "control for" productivity by including material input.
  #' The fitted values from this prediction are purged from measurement error.
  
  #' @param output Output variable. Can be quantity or revenue.
  #' @param labor Labor input column.
  #' @param capital Capital input column.
  #' @param material Material input column, e.g. input goods.
  #' Needs to correlate with productivity so that the firm only
  #' chooses more material when the productivity shock is high.
  #' @param idvar ID variable of the firm in the data set.
  #' @param timevar Time variable of the firm in the data set.
  #' @param degree Degree of the polynomial.
  #' * 1 for Cobb-Douglas production function.
  #' * 2 for Translog productivity.
  #' @return optim output inlcuding estimated parameters.
  input <- polym(labor, capital, material, degree = 2, raw = TRUE)

  first_stage <- lm(output ~ input)
  param0 <- first_stage$coef[c(FALSE, attributes(input)$degree <= degree)]
  param0 <- param0[1:(degree^2 + 1)] + rnorm(degree^2 + 1, 0, 0.01)

  result <- optim(par = param0, fn = gmm_loss,
    idvar = idvar, timevar = timevar,
    output_pred = fitted(first_stage), input = input,
    method = "BFGS")

    return(result)
}

# Test ground
prod_est(chilean$Y, chilean$fX2, chilean$sX, chilean$pX, chilean$idvar, chilean$timevar, degree = 1)

# prodestACF gives the same Cobb-Douglas results for the Chilean test data.
# prodestACF does not allow for a translog production function.
prodestACF(chilean$Y, chilean$fX2, chilean$sX, chilean$pX, chilean$idvar, chilean$timevar)


# FOr the future, implement bootstrapped stadard errors.
capital <- chilean$sX
labor <- chilean$fX2
material <- chilean$pX
idvar <- chilean$idvar
timevar <- chilean$timevar
degree <- 1
output <- chilean$Y
params <- param0
output_pred <- fitted(first_stage)


polyframe <- data.frame(chilean$fX2, chilean$sX, chilean$pX)
head(model.matrix(~.^2 - 1, data = polyframe))

perform_block_bootstrap <- function(df, num_bootstraps = 1000) {
    n <- nrow(df)
    # Sample with replacement, maintaining block structure
    bootstrap_estimates <- numeric(length = num_bootstraps)
    for (i in 1:num_bootstraps) {
        bootstrap_sample <- df[sample(1:n, replace = TRUE), ]
        bootstrap_estimates[i] <- prod_est(bootstrap_sample,
            "prod_value", "employees", "capital", "input_goods")
        }

    return(bootstrap_estimates)
  }
