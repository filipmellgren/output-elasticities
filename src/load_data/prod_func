library(prodest)
library(data.table)
library(boot)
data(chilean)
head(chilean)

gmm_loss <- function(params, d) {
  
  degree <- sqrt(length(params) - 1)

  prod_vars <- polym(d$labor, d$capital, degree = degree, raw = TRUE)
  d$prod_est <- d$output_pred - prod_vars %*% params

  prod_vars.lag <- polym(d$labor.lag, d$capital.lag, degree = degree, raw = TRUE)
  prodest_lag <- d$output.lag - prod_vars.lag %*% params

  g_prod <- polym(prodest_lag, degree = 3, raw = TRUE)

  Z <- polym(d$labor.lag, d$capital, degree = degree, raw = TRUE)
  W <- solve(crossprod(Z)) / nrow(d)

  expected_prod <- fitted(lm(d$prod_est ~ g_prod))

  XI <- d$prod_est - expected_prod # Productivity shocks

  crit <- t(crossprod(Z, XI)) %*% W %*% (crossprod(Z, XI))

  return(crit)
}

prod_est <- function(output, labor, capital, material, idvar, timevar, degree = 2, num_bootstrap = 10) {
  #' Estimate production function parameters
  #' Caution: Results can be unstable and depend on optimization algorithm.
  #' Need to implement bootstrapped standard errors to quantify uncertainty.
  #' 
  #' In the first stage, predict the production function.
  #' we "control for" productivity by including material input.
  #' The fitted values from this prediction are purged from measurement error.
  
  #' @param output Output variable. Can be quantity or revenue.
  #' @param labor Labor input column.
  #' @param capital Capital input column.
  #' @param material Material input column, e.g. input goods.
  #' Needs to correlate with productivity so that the firm only
  #' chooses more material when the productivity shock is high.
  #' @param idvar ID variable of the firm in the data set.
  #' @param timevar Time variable of the firm in the data set.
  #' @param degree Degree of the polynomial.
  #' * 1 for Cobb-Douglas production function.
  #' * 2 for Translog productivity.
  #' @return optim output inlcuding estimated parameters.
  input <- polym(labor, capital, material, degree = 2, raw = TRUE)

  first_stage <- lm(output ~ input)
  param0 <- first_stage$coef[c(FALSE, attributes(input)$degree <= degree)]
  param0 <- param0[1:(degree^2 + 1)] + rnorm(degree^2 + 1, 0, 0.01)

  d <- data.table(input)
  d$idvar <- idvar
  d$timevar <- timevar

  d$output_pred <- fitted(first_stage)
  setnames(d, c("1.0.0", "0.1.0"), c("labor", "capital"))

  d$labor.lag <- lagPanel(idvar, timevar, d$labor)
  d$capital.lag <- lagPanel(idvar, timevar, d$capital)
  d$output.lag <- lagPanel(idvar, timevar, d$output_pred)

  d <- na.omit(d)

  b <- boot::boot(data.frame(d),
    function(x, i) optim(par = param0, fn = gmm_loss, d = x[i, ], method = "BFGS")$par,
    R = num_bootstrap, parallel = "multicore")

  return(b)
}

# Test ground

prod_est(chilean$Y, chilean$fX2, chilean$sX, chilean$pX, chilean$idvar, chilean$timevar, degree = 1, num_bootstrap = 100)


# prodestACF gives the same Cobb-Douglas results for the Chilean test data.
# prodestACF does not allow for a translog production function.
prodestACF(chilean$Y, chilean$fX2, chilean$sX, chilean$pX, chilean$idvar, chilean$timevar)